{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import requests\n",
    "import bs4\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['https://www.nytimes.com/2020/12/16/technology/facebook-takes-the-gloves-off-in-feud-with-apple.html',\n",
       " 'https://www.nytimes.com/2020/12/13/business/media/apple-gawker-tim-cook.html',\n",
       " 'https://www.nytimes.com/2020/12/23/business/dealbook/trump-stimulus-veto.html',\n",
       " 'https://www.nytimes.com/2020/12/01/technology/amazon-apple-chips-intel-arm.html',\n",
       " 'https://www.nytimes.com/2020/12/17/business/dealbook/tech-apple-facebook-fight.html',\n",
       " 'https://www.nytimes.com/2020/12/17/technology/google-antitrust-monopoly.html',\n",
       " 'https://www.nytimes.com/2020/12/15/technology/big-tech-regulation-europe.html',\n",
       " 'https://www.nytimes.com/2020/12/14/technology/big-tech-lobbying-europe.html',\n",
       " 'https://www.nytimes.com/2020/12/09/technology/personaltech/amazon-halo-review.html',\n",
       " 'https://www.nytimes.com/2020/11/18/technology/apple-app-store-fee.html']"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "response = requests.get(\"https://api.nytimes.com/svc/search/v2/articlesearch.json?q=apple&fq=news_desk:Business&api-key=fO0tDSRQQdU68GkuXbMjt1uA2FYImzVp\").json()\n",
    "docs = response['response']['docs']\n",
    "url_list = []\n",
    "for item in docs:\n",
    "    url_list.append(item['web_url'])\n",
    "article_list = []\n",
    "url_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "title = []\n",
    "abstract = []\n",
    "for url in url_list:\n",
    "    time.sleep(0.5)\n",
    "    headers = {'user-agent': 'Mozilla/5.0 (X11; CrOS x86_64 8172.45.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.64 Safari/537.36'}\n",
    "    article = requests.get(url, headers = headers)\n",
    "    soup = bs4.BeautifulSoup(article.content, 'html.parser')\n",
    "    article_text_p = soup.find_all('p', attrs={'class': 'css-axufdj evys1bk0'})\n",
    "    abstract_text_p = soup.find('p', attrs={'class': 'css-w6ymp8 e1wiw3jv0'})\n",
    "    title_text_h1 = soup.find('h1', attrs={'data-test-id': 'headline'})\n",
    "    temp = []\n",
    "    title.append(title_text_h1.text)\n",
    "    abstract.append(abstract_text_p.text)\n",
    "    \n",
    "    for item in article_text_p:\n",
    "        temp.append(item.text)\n",
    "    space = ' '\n",
    "    article_text = space.join(temp)\n",
    "    text.append(article_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Facebook Takes the Gloves Off in Feud With Apple',\n",
       " 'The social network said it opposed changes that Apple was making to the tracking of apps and would provide information for an antitrust complaint against the iPhone maker.',\n",
       " 'For years, signs of discord have brewed between Facebook and Apple.',\n",
       " 'Their chief executives, Apple’s Tim Cook and Facebook’s Mark Zuckerberg, have periodically taken thinly veiled shots at each other.',\n",
       " 'If they’re making money mainly by collecting gobs of personal data, I think you have a right to be worried  Mr. Cook said of companies like Facebook in 2014.',\n",
       " 'In turn, Mr. Zuckerberg has retorted: You think because you’re paying Apple that you’re somehow in alignment with them?',\n",
       " 'If you were in alignment with them, then they’d make their products a lot cheaper.',\n",
       " ' But now Apple is making changes that threaten Facebook’s business — and the fight has intensified.',\n",
       " 'Early next year, Apple plans to start requiring iPhone owners to explicitly choose whether to allow companies to track them across different apps, a practice that Facebook relies on to target ads and charge advertisers more.',\n",
       " 'On Wednesday, Facebook went on the offensive to forestall Apple’s changes.',\n",
       " 'The social network created a website that slammed Apple’s moves as potentially hurtful to small businesses.',\n",
       " '(It did not mention that the changes could hurt itself.) To reinforce its displeasure, Facebook also took out full-page ads in The New York Times, The Wall Street Journal and The Financial Times to declare that it was standing up to Apple.',\n",
       " ' And then to doubly emphasize its point, Facebook said it would provide information for an antitrust suit against Apple filed by Epic Games, the maker of Fortnite, so that the court would understand the unfair policies that Apple imposes.',\n",
       " ' In a blog post, Dan Levy, a vice president for advertising at Facebook, said the company was taking the steps now because we’ve heard from many of you, small businesses in particular, that you are concerned about how Apple’s changes will impact your ability to effectively reach customers and grow — let alone survive in a pandemic.',\n",
       " ' He added, So we’re speaking up for small businesses.',\n",
       " ' Apple executives have expected Facebook’s protests and, in recent weeks, have vowed to go forward with the planned changes.',\n",
       " 'It’s already clear that some companies are going to do everything they can to stop the App Tracking Transparency feature  Craig Federighi, Apple’s software chief, said in a speech last week.',\n",
       " 'We need the world to see those arguments for what they are: a brazen attempt to maintain the privacy-invasive status quo.',\n",
       " ' On Wednesday, in response to Facebook’s public challenge, Apple said it was standing up for its users, who should know when their data is being collected and shared across other apps and websites.',\n",
       " ' The company added that Facebook did not need to stop tracking users or creating targeted advertising, but that it simply requires they give users a choice.',\n",
       " ' The escalating tensions are part of an unusual, high-stakes battle between two of the world’s most valuable companies, which rely on each other and exert tremendous influence over digital behavior.',\n",
       " 'At the heart of the fight is how Facebook and Apple are diametrically opposed on how they make money — and which company wins out is likely to help shape the internet for years to come.',\n",
       " 'Apple prefers that consumers pay for their internet experience, leaving less need for advertisers, while Facebook favors making the internet free for the public, with the bill footed by companies that pay to show people ads.',\n",
       " 'The fracas is also a reminder of both companies’ power over the internet, as well their leverage over each other.',\n",
       " 'Facebook needs its apps to work on Apple’s devices to reach hundreds of millions of people.',\n",
       " 'And Apple needs Facebook’s apps — Facebook, Instagram, WhatsApp and Messenger — to make its devices worth their high price tags.',\n",
       " 'That precarious relationship has underpinned their larger fight, with both careful not to do anything to blow it up.',\n",
       " 'All of this is a long time coming  said Ben Bajarin, principal analyst at Creative Strategies, a tech-research firm in Silicon Valley.',\n",
       " 'A lot of the privacy moves that Apple has made over the past few years, in terms of allowing people to understand what’s happening to them in the background, a lot of it has to do with Facebook.',\n",
       " ' Mr. Cook and Mr. Zuckerberg have long made clear their distaste for the other’s philosophies on advertising, targeting and privacy.',\n",
       " 'In 2018, scandal engulfed Facebook over the news that the voter-profiling company Cambridge Analytica had harvested the Facebook data of more than 50 million people.',\n",
       " 'When Mr. Cook was asked on national television what he would do if he were Mr. Zuckerberg, he replied, What would I do?',\n",
       " 'I wouldn’t be in this situation.',\n",
       " ' He added that it was beyond time that Facebook was regulated.',\n",
       " 'We could make a ton of money if we monetized our customer — if our customer was our product  Mr. Cook said, referring to Facebook’s business model.',\n",
       " 'We’ve elected not to do that.',\n",
       " ' Mr. Zuckerberg responded by calling Mr. Cook’s comments extremely glib.',\n",
       " ' He said, It’s important that we don’t all get Stockholm syndrome and let the companies that work hard to charge you more convince you that they actually care more about you.',\n",
       " '  Then the fight went beyond words.',\n",
       " 'Last year, Apple became upset when Facebook bypassed the iPhone App Store process to distribute an app that paid users $20 if they allowed the app to snoop on their online activity.',\n",
       " 'In response, Apple temporarily blocked some iPhone apps that Facebook employees used to message each other, catch shuttle buses around Facebook’s campus and check the cafeteria menu.',\n",
       " 'That power that Apple wields over which apps appear on iPhones and how they work is now at the center of antitrust probes against the company.',\n",
       " 'And Facebook was again at the receiving end of that clout this year when Apple blocked its new Facebook Gaming app from distribution in its App Store.',\n",
       " 'Apple rejected at least five versions of Facebook Gaming, citing its rules that prohibit apps with the main purpose  of distributing casual games.',\n",
       " 'At the time, people close to Facebook said that Apple’s moves may have been influenced by how Facebook Gaming appeared to compete with Apple’s own sales of games.',\n",
       " 'Then in August, Epic sued Apple, accusing the company of violating antitrust laws by forcing developers to use its payment systems.',\n",
       " 'On Wednesday, Facebook signaled that it was on Epic’s side, saying it was committed to providing relevant information in the Epic Games litigation regarding how Apple’s policies have adversely impacted Facebook and the people and businesses who use our services.',\n",
       " ' All the while, the two companies have sparred over data and privacy.',\n",
       " 'In June, Apple flexed its muscles over the issue, this time with a potential long-term effect on Facebook’s business.',\n",
       " 'That was when Apple announced changes to iPhone software that would blunt the ability of companies like Facebook to collect data on iPhone users.',\n",
       " 'The changes included enabling people to share their approximate location, instead of a precise one, and adding easy-to-read summaries to the App Store on what data each app collects.',\n",
       " 'Most concerning for Facebook, however, was a change that would require iPhone owners to grant apps explicit permission to track them across different apps.',\n",
       " 'Under that policy, most people would probably block Facebook from collecting such information.',\n",
       " 'Facebook uses such data to build robust profiles of its users that it then markets to advertisers.',\n",
       " 'Analysts said the change would probably have a limited impact on Facebook’s main ad business, as it already knows plenty about its users’ interests from their activity on Facebook and Instagram.',\n",
       " 'But they said it could hurt Facebook’s efforts to sell ads in other places around the internet.',\n",
       " 'Facebook’s enormous trove of user data is also one of its most valuable assets.',\n",
       " 'What could be at stake is some future business that Facebook thinks is the next big thing that they can’t get without this data  Mr. Bajarin said.',\n",
       " 'For now, Apple and Facebook hardly compete, save for some limited areas, like Facebook Portal, a screen that Facebook sells for video chatting.',\n",
       " 'But both companies are working toward what many in Silicon Valley believe is the next big thing in computing — augmented reality, or a way to mix digital images into a person’s view of the real world — and analysts expect that race to put them on a collision path.',\n",
       " 'By the time it publicly blasted Apple on Wednesday, Facebook had already taken a shot at its frenemy this week, on Monday.',\n",
       " 'When authorities in Europe were preparing new proposals to regulate tech companies, including a measure to require more transparency on ad targeting, Facebook responded with a statement saying it welcomed regulation — but wondered why the regulators had not taken aim at Apple, too.',\n",
       " 'Apple controls an entire ecosystem from device to app store and apps, and uses this power to harm developers and consumers  the company said, as well as large platforms like Facebook.',\n",
       " '']"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "# Word Tokenization to sentences\n",
    "\n",
    "tokenized_by_sentence = []\n",
    "for num in range(len(text)):\n",
    "    del_quo = re.sub(\",”\", \" \", text[num])\n",
    "    del_quo_2  = re.sub(\"”\", \" \", del_quo)\n",
    "    del_quo_3 = re.sub(\"“\", \"\", del_quo_2)\n",
    "    text_token = re.split(\"(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|!|;|”)\\s\", del_quo_3)\n",
    "    text_token.insert(0, abstract[num])\n",
    "    text_token.insert(0, title[num])\n",
    "    tokenized_by_sentence.append(text_token)\n",
    "\n",
    "tokenized_by_sentence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\yok018\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package twitter_samples to\n[nltk_data]     C:\\Users\\yok018\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package twitter_samples is already up-to-date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     C:\\Users\\yok018\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     C:\\Users\\yok018\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "# Goal of this part: Read through all positive / negative tweets, normalize and remove unnecessary words from tweets, then create actual dictionary-like to use for our dataset\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('twitter_samples')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import twitter_samples\n",
    "\n",
    "pos_tweet = twitter_samples.tokenized('positive_tweets.json')\n",
    "neg_tweet = twitter_samples.tokenized('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all complex part-of-speech to basic words\n",
    "# List of part-of-speech is in this link: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "# WordNetLemmatizer has a function lemmatize where you can convert complex part of speech words into basic forms\n",
    "# Things to consider:\n",
    "#   Remove all unnecessary words from normalized_neg_tweets / normalized_pos_tweets\n",
    "#   1. Remove mentions(starts with @)\n",
    "#   2. Remove links (starts with https:// or http:// )\n",
    "#   3. Remove punctuation (starts with ! or ?)\n",
    "#   4. Remove Stop-Words (words that do have little to no meaning and does not affect the context of the sentence) to make our dataset more concise\n",
    "# Note that we are keeping emoji (i.e. :) or :( . That is because these emojis do actually show sentiment of the text context)\n",
    "# If words are DETERMINERS (DT), COORDINATING CONJUCTIONS (CC), PREPOSITIONS (IN), PERSONAL / POSSESSIVE PRONOUNS (PRP / PRP$), or WH-PRONOUNS (WP) WH-ADVERB(WRB), we remove it (consider as Stop words)\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "normalizer = WordNetLemmatizer()\n",
    "punctuation = ['!', '\"', '#', '$' ,'%', '&', \"'\",'(',')','*','+',',','-','.',':',';','<','=','>','?','@','[','],''^','_','`','{','|','}','~']\n",
    "\n",
    "def determiners(word):\n",
    "    for i in word:\n",
    "        if i in punctuation:\n",
    "            return False\n",
    "    if word.startswith('@') or word.startswith('!') or word.startswith('?') or word.startswith('https://') or word.startswith('http://'):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def normalize(tweet_list):\n",
    "    normalized_tweet = []\n",
    "    for tweet in tweet_list:\n",
    "        sentence = []\n",
    "        for token, tag in pos_tag(tweet):\n",
    "            # For Complex Noun words:\n",
    "            if tag.startswith('NN'):\n",
    "                new_tag = 'n'\n",
    "            # For Complex Verb words\n",
    "            elif tag.startswith('VB'):\n",
    "                new_tag = 'v'\n",
    "            # For stop-words\n",
    "            elif tag.startswith('DT') or tag.startswith('CC') or tag.startswith('IN') or tag.startswith('PRP') or tag.startswith('PRP$') or tag.startswith('WP') or tag.startswith('WRB'):\n",
    "                continue \n",
    "            # Every other words, convert them into adjective (pos = 'a')\n",
    "            else:\n",
    "                new_tag = 'a'\n",
    "            sentence.append(normalizer.lemmatize(token, new_tag))\n",
    "        new_sentence = [ word for word in sentence if determiners(word) ]\n",
    "        normalized_tweet.append(new_sentence)\n",
    "    return normalized_tweet\n",
    "\n",
    "normalized_pos_tweets = normalize(pos_tweet)\n",
    "normalized_neg_tweets = normalize(neg_tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the stop words\n",
    "# borrowed list of stop words from https://github.com/kavgan/stop-words/blob/master/terrier-stop.txt \n",
    "\n",
    "filepath = open(\"terrier-stop.txt\", \"r\")\n",
    "stop_words = filepath.read().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, store all positive / negative words into dictionary so it can be used as a guide for calculating sentiment for sentences\n",
    "pos_words_dict = {}\n",
    "neg_words_dict = {}\n",
    "\n",
    "# Store all words into dictionary\n",
    "for tweet in normalized_pos_tweets:\n",
    "    for word in tweet:\n",
    "        if word in stop_words:\n",
    "            continue\n",
    "        elif word in pos_words_dict:\n",
    "            temp = pos_words_dict[word.lower()]\n",
    "            temp += 1\n",
    "            pos_words_dict[word.lower()] = temp\n",
    "        else:\n",
    "            pos_words_dict[word.lower()] = 1\n",
    "\n",
    "for tweet in normalized_neg_tweets:\n",
    "    for word in tweet:\n",
    "        if word in stop_words:\n",
    "            continue\n",
    "        elif word in neg_words_dict:\n",
    "            temp = neg_words_dict[word.lower()]\n",
    "            temp += 1\n",
    "            neg_words_dict[word.lower()] = temp\n",
    "        else:\n",
    "            neg_words_dict[word.lower()] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all emojis and leave only roman alphabets\n",
    "pos_df = pd.DataFrame({'word': list(pos_words_dict.keys()), 'frequency': list(pos_words_dict.values())})\n",
    "cleaned_pos_df = pos_df.loc[pos_df['word'].str.isalpha()]\n",
    "\n",
    "neg_df = pd.DataFrame({'word': list(neg_words_dict.keys()), 'frequency': list(neg_words_dict.values())})\n",
    "cleaned_neg_df = neg_df.loc[neg_df['word'].str.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign scales according to frequency between absolute values 1 to 5 (-1 to -5 for negative words)\n",
    "cleaned_pos_df['scale'] = cleaned_pos_df['frequency'] * (4 / cleaned_pos_df['frequency'].max()) + 1\n",
    "cleaned_neg_df['scale'] = cleaned_neg_df['frequency'] * (-4 / cleaned_neg_df['frequency'].max()) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "string index out of range",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-2d83eb95cdfe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenized_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mtokenized_by_sentence_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer_myself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenized_by_sentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mtokenized_by_sentence_new\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-59-2d83eb95cdfe>\u001b[0m in \u001b[0;36mtokenizer_myself\u001b[1;34m(given_articles)\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtokenized_sentence\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                 \u001b[0mtemp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenized_sentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mnew_temp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mtokenized_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_temp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtokenized_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-7745e3d16998>\u001b[0m in \u001b[0;36mnormalize\u001b[1;34m(tweet_list)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweet_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0msentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m             \u001b[1;31m# For Complex Noun words:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'NN'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tag\\__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[1;34m(tokens, tagset, lang)\u001b[0m\n\u001b[0;32m    159\u001b[0m     \"\"\"\n\u001b[0;32m    160\u001b[0m     \u001b[0mtagger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tag\\__init__.py\u001b[0m in \u001b[0;36m_pos_tag\u001b[1;34m(tokens, tagset, tagger, lang)\u001b[0m\n\u001b[0;32m    116\u001b[0m         )\n\u001b[0;32m    117\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mtagged_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtagset\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Maps to the specified tagset.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlang\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"eng\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tag\\perceptron.py\u001b[0m in \u001b[0;36mtag\u001b[1;34m(self, tokens, return_conf, use_tagdict)\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m         \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTART\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEND\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m             tag, conf = (\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tag\\perceptron.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m         \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTART\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEND\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m             tag, conf = (\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tag\\perceptron.py\u001b[0m in \u001b[0;36mnormalize\u001b[1;34m(self, word)\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;34m\"!YEAR\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m         \u001b[1;32melif\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;34m\"!DIGITS\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "# tokenize and lametize the article from new york times\n",
    "\n",
    "def tokenizer_myself(given_articles):\n",
    "    tokenized_result = []\n",
    "    for article_iter in given_articles: \n",
    "        temp = []\n",
    "        for sentence in article_iter:\n",
    "            tokenized_sentence = sentence.split(\" \")\n",
    "            if tokenized_sentence:\n",
    "                temp.append(tokenized_sentence)\n",
    "        new_temp = normalize(temp)\n",
    "        tokenized_result.append(new_temp)\n",
    "    return tokenized_result\n",
    "\n",
    "tokenized_by_sentence_new = tokenizer_myself(tokenized_by_sentence)\n",
    "\n",
    "tokenized_by_sentence_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Facebook', 'Takes', 'the', 'Gloves', 'Off', 'in', 'Feud', 'With', 'Apple']"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}