{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\cheol\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package twitter_samples to\n[nltk_data]     C:\\Users\\cheol\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package twitter_samples is already up-to-date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     C:\\Users\\cheol\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     C:\\Users\\cheol\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import requests\n",
    "import bs4\n",
    "import json\n",
    "import re\n",
    "\n",
    "import tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_prices(ticker):\n",
    "    \"\"\"\n",
    "    ticker is the abbreviated symbol for a stock e.g.AAPL\n",
    "    this function returns the daily price history of the requested stock as a dataframe\n",
    "    \"\"\"\n",
    "    stock_endpoint = 'https://financialmodelingprep.com/api/v3/historical-price-full/'\n",
    "    response = requests.get(stock_endpoint + ticker + '?apikey=70407133ea11d7284c70bbca4eee2547').json()\n",
    "    type(response) == dict\n",
    "    return pd.DataFrame(response['historical'])\n",
    "\n",
    "def ny_times_articles(keyword):\n",
    "    url_dict = {}\n",
    "    index = 0\n",
    "    for i in range(10):\n",
    "        response = requests.get(\"https://api.nytimes.com/svc/search/v2/articlesearch.json?q=\"+ keyword +\"&fq=news_desk:Business&page=\"+str(i)+\"&api-key=fO0tDSRQQdU68GkuXbMjt1uA2FYImzVp\").json()\n",
    "        try:\n",
    "            docs = response['response']['docs']\n",
    "            for item in docs:\n",
    "                if item['web_url'][8] == 'w': # To remove 'https://bits.blogs.nytimes...' or ''https://dealbook.nytimes...'\n",
    "                    link = item['web_url']\n",
    "                    date = link[24:28] + '-' + link[29:31] + '-' + link[32:34]\n",
    "                    url_dict[index] = tuple((link, date))\n",
    "                    index += 1\n",
    "        except KeyError:\n",
    "            continue\n",
    "    return url_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = stock_prices('AAPL')\n",
    "url_dict = ny_times_articles('apple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            date       price    change  pct_change\n",
       "0     2020-12-31  132.690002       NaN         NaN\n",
       "1     2020-12-30  133.720001  1.029999    0.007703\n",
       "2     2020-12-29  134.869995  1.149994    0.008527\n",
       "3     2020-12-28  136.690002  1.820007    0.013315\n",
       "4     2020-12-24  131.970001 -4.720001   -0.035766\n",
       "...          ...         ...       ...         ...\n",
       "1254  2016-01-08   24.240000 -0.392500   -0.016192\n",
       "1255  2016-01-07   24.112499 -0.127501   -0.005288\n",
       "1256  2016-01-06   25.174999  1.062500    0.042205\n",
       "1257  2016-01-05   25.677500  0.502501    0.019570\n",
       "1258  2016-01-04   26.337500  0.660000    0.025059\n",
       "\n",
       "[1259 rows x 4 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>price</th>\n      <th>change</th>\n      <th>pct_change</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2020-12-31</td>\n      <td>132.690002</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2020-12-30</td>\n      <td>133.720001</td>\n      <td>1.029999</td>\n      <td>0.007703</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2020-12-29</td>\n      <td>134.869995</td>\n      <td>1.149994</td>\n      <td>0.008527</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2020-12-28</td>\n      <td>136.690002</td>\n      <td>1.820007</td>\n      <td>0.013315</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2020-12-24</td>\n      <td>131.970001</td>\n      <td>-4.720001</td>\n      <td>-0.035766</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1254</th>\n      <td>2016-01-08</td>\n      <td>24.240000</td>\n      <td>-0.392500</td>\n      <td>-0.016192</td>\n    </tr>\n    <tr>\n      <th>1255</th>\n      <td>2016-01-07</td>\n      <td>24.112499</td>\n      <td>-0.127501</td>\n      <td>-0.005288</td>\n    </tr>\n    <tr>\n      <th>1256</th>\n      <td>2016-01-06</td>\n      <td>25.174999</td>\n      <td>1.062500</td>\n      <td>0.042205</td>\n    </tr>\n    <tr>\n      <th>1257</th>\n      <td>2016-01-05</td>\n      <td>25.677500</td>\n      <td>0.502501</td>\n      <td>0.019570</td>\n    </tr>\n    <tr>\n      <th>1258</th>\n      <td>2016-01-04</td>\n      <td>26.337500</td>\n      <td>0.660000</td>\n      <td>0.025059</td>\n    </tr>\n  </tbody>\n</table>\n<p>1259 rows Ã— 4 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# use the closing prices of the stock as the daily prices and the differences in each day as the percentage rise or fall\n",
    "# the difference of stock prices between date1 and date2 will be stored in the row of date1 for ease of comparison\n",
    "\n",
    "prices = stocks['close']\n",
    "dates = stocks['date']\n",
    "difference = stocks['close'].astype('float64').diff()\n",
    "pct_change = difference / prices\n",
    "\n",
    "stock = pd.DataFrame({'date': dates, 'price':prices, 'change': difference, 'pct_change': pct_change})\n",
    "stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = tokenizer.tokenize_sentence(url_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = tokenizer.merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_word = tokenizer.tokenizer_myself(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vals = tokenizer.sentence_calculator(tokenized_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-d7682d4bf648>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0marticle_vals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalculate_vals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\cheol\\Projects\\sentiment_analysis\\tokenizer.py\u001b[0m in \u001b[0;36mcalculate_vals\u001b[1;34m(articles_lst)\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0marticle\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marticles_lst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[0mnew_article\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilter_one\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marticle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m         \u001b[0mavg_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_article\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_article\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_article\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m         \u001b[0mavg_score_article\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavg_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mavg_score_article\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "article_vals = tokenizer.calculate_vals(sentence_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}